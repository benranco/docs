To log into the NFIS openstack system:
ssh brancourt@borealjump.nfis.org
Then:
source quickstart/openrc.sh


              RAM   CPU AVAILABLE
x1.16xlarge   1015  64  2          not public (but I have access)
mm2e.16xlarge 1000  56  1          not public
x1.8xlarge    507   32  4          not public
mm1.16xlarge  252   56  8
gp2e.4xlarge  122   56  10
gp2.4xlarge   57    56  22
gp1.4xlarge   28    56  4
mm1.8xlarge   126   28  16
mm1.4xlarge   72    16  28

To mount a folder in /public as a volume:
From jump:
cd /public
df to show full path of /public
From your vm:
mount a folder from /public as nfs

[brancourt@jump2 ~]$ ls /public/genomics/
junjun_Conifer_192gDNA  out01  out02  out03  out04  out05  out06  out07  out08  out09  out10
[brancourt@jump2 genomics]$ df
Filesystem          1K-blocks       Used   Available Use% Mounted on
/dev/vda1            51474024    4015968    44820288   9% /
devtmpfs              1001040          0     1001040   0% /dev
tmpfs                 1023732          0     1023732   0% /dev/shm
tmpfs                 1023732     115020      908712  12% /run
tmpfs                 1023732          0     1023732   0% /sys/fs/cgroup
10.20.0.6:/Public 99962978816 7547415552 92415563264   8% /public

sudo mount -t nfs 10.20.0.6:/Public/genomics/junjun_Conifer_192gDNA /workin
sudo mount -t nfs 10.20.0.6:/Public/genomics/out01 /work
sudo mount -t nfs 10.20.0.6:/Public/genomics/NCBI-NR /work2
sudo mount -t nfs 10.20.0.6:/Public/genomics/Data-Dec2020/ben2021/a6/blastrun /work
sudo mount -t nfs 10.20.0.6:/Public/genomics/komendja_backup2 /work3
sudo mount -t nfs 10.20.0.6:/Public/genomics/Data-Dec2020/ben2021/a6/orthofinder /work

sudo mount -t nfs 10.20.0.6:/Public/genomics/NCBI-NR /work2
sudo mount -t nfs 10.20.0.6:/Public/genomics/Data-Dec2020/ben2021/a6/blastrun/blast0 /work


List of OpenStack commands:
https://docs.openstack.org/python-openstackclient/latest/cli/command-list.html


===========================

The thing to do when you want a larger root disk (larger than 20 GB), is create the VM using a volume.  In the web interface or using ansible it is easier.  But on the command-line you can do it like so:

openstack volume create --image grdi --bootable --size 50 ben_grdi_vol

openstack server create \
	--volume ben_grdi_vol \
  --flavor mm1.medium \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	ben_grdi

openstack volume create --image biolinux8 --bootable --size 50 ben_bio_vol

openstack server create \
	--volume ben_bio_vol \
  --flavor mm1.medium \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	ben_bio


For ansible, use the example script and add the “boot_from_volume”, “terminate_volume”, and “volume_size”  declarations for the “os_server” task.  See: http://docs.ansible.com/ansible/latest/modules/os_server_module.html


===========================

[<myusername>@jump ~]$ source quickstart/openrc.sh
[<myusername>@jump ~]$ openstack keypair create brancourt > brancourt.pem
[<myusername>@jump ~]$ chmod 0600 mynewkeypair.pem

openstack image list
openstack flavor list


openstack server create \
	--image CentOS7_SNPpipeline \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor x1.8xlarge \
	ben_vm1

openstack server create \
	--image CentOS7_SNPpipeline \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor x1.16xlarge \
	ben_pipeline_vm

openstack server create \
	--image CentOS7_BenWork \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm1.medium \
	ben_t
	
openstack server create \
	--image CentOS7_BenWork \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm1.4xlarge \
	ben_b

openstack server create \
	--image CentOS7_BenWork \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm2.4xlarge \
	ben0

openstack server create \
	--image CentOS7_BenWork \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm1.8xlarge \
	ben0
		
openstack server create \
	--image CentOS7_BenWork \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm2.8xlarge \
	ben0
	
openstack server create \
	--image CentOS7_BenWork \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm1.16xlarge \
	ben0

openstack server create \
	--image CentOS7_BenWork \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor x1.4xlarge \
	ben0

# for VNC vm: 
openstack server create \
	--image CentOS7_GUI_VNC-noInstruct \
  --security-group default \
  --security-group vnc_security_group \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm1.medium \
	ben_v4


openstack server add floating ip ben01a 10.20.0.54
openstack server add floating ip ben01b 10.20.0.134		
openstack server add floating ip ben02a 10.20.0.153         
openstack server add floating ip ben02b 10.20.0.210         
openstack server add floating ip ben03 10.20.0.200         
openstack server add floating ip ben04 10.20.0.203         
openstack server add floating ip ben05 10.20.0.155         
openstack server add floating ip ben06 10.20.0.152         
openstack server add floating ip ben07 10.20.0.196         
openstack server add floating ip ben08 10.20.0.120         
openstack server add floating ip ben09 10.20.0.183         
openstack server add floating ip ben10 10.20.0.207    


openstack floating ip list
openstack floating ip create External

openstack server add floating ip brancourt_vm 10.20.0.54
openstack server add floating ip ben_small_vm 10.20.0.134

openstack server stop brancourt_vm
openstack volume create --size 10 volname_vol
openstack volume create --type qnap1 --size 600 volname_vol # use this if creating a large volume
openstack server add volume brancourt_vm volname_vol
openstack server remove volume brancourt_vm volname_vol
openstack server start brancourt_vm
openstack server delete brancourt_vm

ssh -i brancourt.pem centos@10.20.0.54
scp -i brancourt.pem ./file centos@10.20.0.54:~

[Can copy/download stuff to /projects/genomics on the borealjump server. Can also download directly to my own volume attached to a vm if I want. Could also possibly mount specific folders in /projects/genomics to my vm's?]

# to mount a volume to /work:
sudo mount -t xfs /dev/vdb1 /work
# to unmount:
sudo umount /work

To format and mount a new disk drive to a folder on CentOS 7, from:
https://unix.stackexchange.com/questions/385769/mount-an-entire-drive-to-a-subforlder-centos-7
First:
ls /dev
[It should be something like vdb]
[Create a new partition:]
sudo fdisk /dev/vdb
[follow the directions, select n to create a new partition, use the defaults to fill up the whole disk, then select w to save and exit]
[Format the new partition as xfs:]
sudo mkfs.xfs /dev/vdb1
[Then create a directory at root level to mount it to:]
sudo mkdir /work
sudo mount -t xfs /dev/vdb1 /work
[Then do chmod and chown as desired. These permissions will be saved on the drive itself so you only need to do it once.]
sudo chmod 775 /work
sudo chown centos:centos /work
[To unmount:]
sudo umount /work


For vm's based on the GRDI image, I couldn't format or mount xfs volumes, so I had to do:
sudo yum install xfsprogs-devel
Then I was able to use the mkfs.xfs command to format the volume to xfs, and then mount it. I may or may not have also had to do:
sudo modprobe xfs
But I did this before installing xfsprogs-devel, so I don't know if I actually needed it.



To run a command as a background process, end with an &, but this will terminate if you exit from an ssh session in which you ran the command, so when you want the process to continue even after your ssh session ends, use the nohup (no hangups) command:
nohup command 2>&1 1> log.txt &

To searck for process id by command name:
ps -e | grep name
To kill all processes of a certain command:
pkill -9 name

===================================================
Steps I used to make a CentOS image for running the SNPpipeline on the NFIS boreal cloud:


sudo yum update
sudo yum install nano
sudo yum install git
sudo yum install wget
sudo yum install epel-release
sudo yum install R libcurl-devel.x86_64 libxml2-devel.x86_64

# these were necessary to install so that some required R packages could be successfully installed:
sudo yum install openssl-devel
sudo yum install mariadb-devel

#from wherever you want the SNPpipeline to be downloaded to, enter:
git clone https://github.com/benranco/SNPpipeline.git

# this is where I'll mount an external volume:
mkdir /work
cd ~
ln -s /work work

# after setting the VM up the way i you want it, exit, shut it down, and do:
openstack server image create --name image_name server_name

===================================================




==============

# To create a new security group and add rules to enable ssh in and out:

openstack security group show name

openstack security group create benssh --description "Intended to allow ssh ingress on port 22, as well as egress."

openstack security group rule create benssh \
    --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0 \
    --ingress --ethertype IPv4

openstack security group rule create benssh \
    --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0 \
    --egress --ethertype IPv4




# Or, just to add the rules to enable ssh in and out to the default security group:

openstack security group rule create default \
    --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0 \
    --ingress --ethertype IPv4

openstack security group rule create default \
    --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0 \
    --egress --ethertype IPv4

---
# here's the vnc_security_group: 
openstack security group show vnc_security_group
This revealed four rules, which I've pasted below in more human-readable format: 

RULE 1:
created_at='2019-06-07T21:41:29Z', 
direction='egress', 
ethertype='IPv4', 
id='180b1fbd-1f5e-4dc5-af34-4814c29e2bcf', 
updated_at='2019-06-07T21:41:29Z'

RULE 2:
created_at='2019-06-07T21:43:10Z', 
direction='ingress', 
ethertype='IPv4', 
id='9c4734bf-adf7-4340-9f8e-fe46d12b9dea', 
port_range_max='5901', 
port_range_min='5901', 
protocol='tcp', 
remote_ip_prefix='0.0.0.0/0', 
updated_at='2019-06-07T21:43:10Z'

RULE 3:
created_at='2019-06-07T21:41:29Z', 
direction='egress', 
ethertype='IPv6', 
id='b4a86bab-bcae-49c3-9305-05ccd594bbd9', 
updated_at='2019-06-07T21:41:29Z'

RULE 4:
created_at='2019-06-07T21:43:20Z', 
direction='egress', 
ethertype='IPv4', 
id='f6cd53de-0bd4-48b8-bb2f-7bf8446c56b1', 
port_range_max='5901', 
port_range_min='5901', 
protocol='tcp', 
remote_ip_prefix='0.0.0.0/0', 
updated_at='2019-06-07T21:43:20Z'

---



==============


=======================
[brancourt@jump ~]$ openstack server create --image CentOS7 --key-name brancourt --nic net-id=Private --flavor m4.16xlarge brancourt_vm
Quota exceeded for cores, ram: Requested 50, 262144, but already used 0, 0 of 20, 51200 cores, ram (HTTP 403) (Request-ID: req-bfa42b54-05d7-41b7-b1c8-404f902ee7fc)
[brancourt@jump ~]$ 





